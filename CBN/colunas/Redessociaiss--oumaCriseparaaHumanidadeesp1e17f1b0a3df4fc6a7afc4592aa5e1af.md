# Redes sociais são uma Crise para a Humanidade esperando estourar?

Comentário: Tema polêmico, ir com cuidado
Palavras chave: Redes sociais, instagram, twitter, whatsapp

WOW: Facebook is issuing a cease and desist to my favorite Chrome extension: Unfollow Everything
It unfollows all your FB friends, so you can re-follow people who matter and take back control of your newsfeed
It saved me 1 hour per day.

#intro

Você, eu, nossos amigos e família, a vizinhança, o Brasil, o Mundo! Quem não está cadastrado em pelo menos uma rede social? Se praticamente todo mundo tem smartphone, os incentivos pra estar nelas é gigante. E hoje, o maior deles é o fato de que todos outros estão. E aí, quem se arrisca a ficar de fora? Pra muita gente, as redes são instrumentos de trabalho, inclusive.

Do ponto de vista histórico, o facebook, instagram, WhatsApp, Telegram, Twitter, essas coisas todas são extremamente recentes. O Orkut, aquele que introduziu a gente nesse mundo, começou em 2004, ou seja, meros 15 anos — curioso que o Google, o cuidador do Orkut, nunca mais conseguiu dominar esse mercado, depois de várias tentativas fracassadas.  

Bom, em tão pouco tempo ainda não dá pra ver o efeito que as redes criam na nossa sociedade. Afinal, estamos falando sobre algo que hoje possui um impacto absurdo no comportamento, na economia, na política, na saúde pública, em praticamente tudo, e sobre esse impacto pouco sabemos ainda, cientificamente falando. 

As mídias sociais modificaram drasticamente o jeito como nos comunicamos, em um período muito curto. Podemos agora descobrir pessoas, arrumar encontros, Curtir, clicar e compartilhar informação instantaneamente, direcionados por algoritmos e métodos de cujo funcionamento a maioria de nós não tem a mínima noção.

#artigo

Essa é a justamente a preocupação de um grupo multidisciplinar de 17 cientistas, incluindo sociólogos, biólogos e filósofos, que publicaram um artigo numa revista científica de prestígio, a PNAS, com o título, traduzido livremente aqui por mim, "Guiando o comportamento coletivo".

#mensagem principal do artigo

Bom, no artigo, esse grupo de estudiosos destacam que os impacto das mídias sociais precisa ser estudado com mais afinco, e que o assunto deve ser incluído como "uma disciplina de crise". 

Uma disciplina de crise seria um campo de estudo no qual cientistas de várias áreas trabalham de forma rápida pra tratar de um problema urgente, da mesma forma que a biologia trabalha pra evitar que certas espécies se extingam, ou que a ciência do clima trabalhe para parar o aquecimento global.

Ou seja, elas e eles dizem que devemos estar atentos de forma emergencial ao assunto, sob o risco de termos uma catástrofe de dimensões globais sobre nossa democracia, nossa saúde mental e nossos relacionamentos.

#mais detalhes

O artigo destaca que nossa falta de compreensão sobre os efeitos das novas tecnologias é uma ameaça à democracia e ao progresso científico, usando como exemplo o comportamento dos controladores das redes durante a pandemia da COVID-19, que não teriam conseguido barrar a onda de desinformação que criou as dúvidas em cima do uso de máscaras ou da vacinação. O texto ainda alerta que poderemos, no futuro, observar, impotentes, as redes contribuindo para outros fenômenos ainda mais nocivos, como interferência em eleições, violência extremista, racismo ou até guerras. É difícil não concordar com isso, pelo menos em parte, com algumas coisas que temos visto por aí. O que é raro é ver uma chamada pra ação vir de um grupo tão diverso de cientistas, de tantas áreas diferentes — essa colaboração mostra que essa turma está mesmo preocupada.

#desinformação

Não há dúvida de que as redes sociais mudaram a forma como adquirimos informação, e como formamos nossas opiniões acerca do mundo. É só lembrar de como recebemos notícias no Facebook, ou nos grupos que participamos no WhatsApp. Estamos sempre prontos a receber informação de um jeito predefinido pelo algoritmo da rede social, o método que a rede social, por exemplo, apresenta a notícia pra gente. Por exemplo, tendemos a valorizar a notícia que aparece no topo da página, na hora que abrimos o Instagram, ou o Twitter, esquecendo de que o método que essas redes usam segue uma lógica comercial bem direta e simples: colocar a notícia que, baseado no que a rede já sabe sobre a gente — e olha que eles sabem muita coisa —, aumenta nosso engajamento, independente se essa notícia sequer esbarra na realidade. E pessoas engajadas acessam a rede muito mais vezes, e assim podem visualizar mais anúncios. Não é segredo pra ninguém que a principal fonte de renda de Facebook ou Google é a venda de publicidade, no entanto essa consciência não evita que a gente seja influenciado.

Nisso tudo, somos mais vulneráveis à disseminação de notícias e ideias incompletas ou simplesmente falsas. E elas se espalham de forma absurdamente rápida, de um jeito que nunca foi visto na história. Os cientistas estão preocupados com a maneira orgânica de espalhamento de desinformação, que com pouquíssimo esforço atinge grupos gigantes, países inteiros, e que geram, por exemplo, a invasão de uma massa raivosa ao parlamento da democracia mais madura do mundo. O alerta é que isso, e coisa pior, se torne comum.

So you can have these bits of misinformation that explode at unprecedented velocity in ways that they wouldn’t have prior to this information ecosystem.

[Now], you can create large communities of people that hold constellations of beliefs that are not grounded in reality, [such as [the conspiracy theory] QAnon](https://www.vox.com/policy-and-politics/2018/8/1/17253444/qanon-trump-conspiracy-theory-4chan-explainer). You can have ideas like anti-vaccination ideas spread in new ways. You can create polarization in new ways.

And [you can] create an information environment where misinformation seems to spread organically. And also [these communities can] be extremely vulnerable to targeted disinformation. We don’t even know the scope of that yet.

#algoritmos enviesados

But these systems can be biased based on who builds them, how they’re developed, and how they’re ultimately used. This is commonly known as algorithmic bias. It’s tough to figure out exactly how systems might be susceptible to algorithmic bias, especially since this technology often operates in a corporate black box. We frequently don’t [know](https://www.vox.com/recode/2020/2/5/21120404/police-departments-artificial-intelligence-public-records) how a particular artificial intelligence or algorithm was designed, what data helped build it, or how it works.

Typically, you only know the end result: how it has affected you, if you’re even aware that AI or an algorithm was used in the first place. *Did you get the job?* *Did you see that Donald Trump ad on your Facebook timeline? Did [a facial recognition system](https://www.vox.com/recode/2020/2/11/21131991/clearview-ai-facial-recognition-database-law-enforcement) identify you?* That makes addressing the biases of artificial intelligence tricky, but even more important to understand.

Importantly, when you think of data, you might think of formal studies in which demographics and representation are carefully considered, limitations are weighed, and then the results are peer-reviewed. That’s not necessarily the case with the AI-based systems that might be used to make a decision about you. Let’s take one source of data everyone has access to: the internet. One study found that, by teaching an artificial intelligence to crawl through the internet — and just reading what humans have already written — the system would produce prejudices against black people and women.

**Documentário no Netflix**

So it’s important because it says this needs to be a crisis discipline, this is something that we don’t understand. We don’t have a theory for how all of these changes are affecting the way that people come to form their beliefs and opinions, and then use those to make decisions. And yet, that’s all changing. It’s happening. ...

There’s a misperception that we’re saying, “Exposure to ads is bad — that’s causing the harm.” That’s not what we’re saying. Exposure to ads may or may not be bad. What we’re concerned about is the fact that this information ecosystem has developed to optimize something orthogonal to things that we think are extremely important, like being concerned about the veracity of information or the effect of information on human well-being, on democracy, on health, on the ecosystem.

Those issues are just being left to sort themselves out, without a whole lot of thought or guidance around them.

That puts it in this crisis discipline space. It’s like climate science where you don’t have time to sit down and work out everything definitively. This paper is essentially saying something quite similar — that we don’t have time to wait. We need to start addressing these problems now.

Well, with the printing press, I would push back. The printing press came out and upended history. We’re still recovering from the capacity that the printing press gave to Martin Luther. The printing press radically changed the political landscape in Europe. And, you know, depending on whose histories you go by, you had decades if not centuries of war [after it was introduced].

So, did we somehow recover? Sure we did. Would it have been better to do it in a stewarded way? I don’t know. Maybe. These major transitions in information technology often cause collateral damage. We tend to hope that they also bring about a tremendous amount of good as we move toward human knowledge and all of that. But even the fact that you’ve survived doesn’t mean that it’s not worth thinking about how to get through it smoothly.

It reminds me of one of the least intelligent critiques of the [Covid-19] vaccines that we’re using now: “We didn’t have vaccines during the Black Death plague. And we’re still here.” We are, but it took out a third of the population of Europe.

One important defense of social media is that Facebook and Twitter can be places where people share new ideas that are not mainstream that end up being right. Sometimes media gatekeepers can get things wrong and social media can allow better information to come out. For example, some people like [Zeynep Tufekci were sounding the alarm](https://www.vox.com/recode/2020/4/13/21214114/media-coronavirus-pandemic-coverage-cdc-should-you-wear-masks) on the pandemic early, largely on Twitter, back in February 2020, far ahead of the CDC and most journalists.

Yeah, to look at the net, you have to look at the net influence of the system, right? If somebody on social media has things right but if the net influence on social media is to promote anti-vaccination sentiment in the United States to the point that we’re not going to be able to reach herd immunity, it doesn’t let social media off the hook. ...

I was enormously optimistic about the internet in the ’90s. [I thought] this really was going to remove the gatekeepers and allow people who did not have financial, social, and political capital to get their stories out there.

And it’s certainly possible for all that to be true and for the concerns that we express in our paper to also be correct.

That’s one of the real challenges that we’re facing, actually, is that we don’t have a lot of information. We need to figure out how, to what degree, people have been exposed to misinformation, to what degree is that influencing subsequent online behavior. All of this information is held exclusively by the tech companies that are running these platforms.

[Editor’s note: Most major social media companies work with academics who research their platforms’ effects on society, [but the companies restrict and control how much information researchers can use](https://techcrunch.com/2021/06/02/facebook-to-launch-a-researcher-api-for-the-academic-community/).]

For me, a crisis discipline is a situation where you don’t have all of the information that you need to know exactly what to do, but you don’t have time to wait to figure it out.

This was the situation with Covid in February or March 2020. We’re definitely in that position with global climate change. We’ve got better models than we did 20 years ago, but we still don’t have a complete description of how that system works. And yet, we certainly don’t have time to wait around and figure all that out.

And here, I think that the speed with which social media, combined with a whole number of other things, has led to very widespread disinformation — [that] here in the United States [is] causing major political upheaval — is striking. How many more elections do you think we have before things get substantially worse?

So there are these super-hard problems that take radical transdisciplinary work. We need to figure out how to come together and talk about all that. But at the same time, we have to be taking actions.

How do you respond to the chicken-and-egg argument? You hear defenders of technology say, “We’re just seeing real-world polarization reflected online,” but there’s no proof that the internet is causing polarization.

### Carl Bergstrom

This should be a familiar argument. This is what Big Tobacco used, right? This is [Merchants of Doubt stuff](https://www.vox.com/2015/3/21/8267049/merchants-of-doubt). They said, “Well, you know, yeah, sure, lung cancer rates are going up, especially among smokers — but there’s no proof it’s been caused by that.”

And now we’re hearing the same thing about misinformation: “Yeah, sure, there’s a lot of misinformation online, but it doesn’t change anyone’s behavior.” But then all of a sudden you got a guy in a loincloth with buffalo horns running around the Capitol building.

I’m biased to be very aware of this problem because my job is to report on social media, but it feels like there is a lot of fear and concern about social media’s impact. Misinformation, phone addiction — these seem to be issues that everyday people worry about. Why do you think there still isn’t enough attention on this?

### Carl Bergstrom

When I talk to people about social media, yes, there’s a lot of concern, there’s a lot of negativity, and then there’s bias by being a parent as well. But the focus is often on the individual-level effects. So it’s, “My kids are developing negative issues around self-esteem because of the way that Instagram is structured to get ‘Likes’ for being perfect and showing more of your body.”

But there’s less talk about the entire large-scale structural changes that this is inducing. So what we’re saying is, we really want people to look at the large-scale structural changes that these technologies are driving in society.

[som de notificação]

Oba, alguém curtiu minha foto!

Um abraço e até a próxima,